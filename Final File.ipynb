{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd91e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF Setup for memory control\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "seq_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c174031",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / batch_size)\n",
    "    \n",
    "    for start in range(0, batch_chars - seq_length, 64):\n",
    "        X = np.zeros((batch_size, seq_length))\n",
    "        Y = np.zeros((batch_size, seq_length, unique_chars))\n",
    "        for batch_index in range(0, 16):\n",
    "            for i in range(0, 64):\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = M.Sequential()\n",
    "    model.add(L.Embedding(input_dim = 87, output_dim = 512, batch_input_shape = (batch_size, seq_length))) \n",
    "    model.add(L.LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(L.Dropout(0.1))\n",
    "    model.add(L.LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(L.Dropout(0.1))\n",
    "    model.add(L.LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(L.Dropout(0.1))\n",
    "    model.add(L.TimeDistributed(Dense(87)))\n",
    "    model.add(L.Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data,load=False,epochs=100):\n",
    "    with open('char_to_index.json') as json_file:\n",
    "        char_to_index = json.load(json_file)\n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    model = M.Sequential()\n",
    "    model.add(L.Embedding(input_dim = 87, output_dim = 512, batch_input_shape = (batch_size, seq_length))) \n",
    "    model.add(L.LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(L.Dropout(0.1))\n",
    "    model.add(L.LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(L.Dropout(0.1))\n",
    "    model.add(L.LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(L.Dropout(0.1))\n",
    "    model.add(L.TimeDistributed(Dense(87)))\n",
    "    model.add(L.Activation(\"softmax\"))\n",
    "    if load:\n",
    "        model.load_weights(\"weights/weights.h5\", by_name=True)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    loss, accuracy = [], []\n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0    \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, 87)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y)\n",
    "        clear_output()\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=[20,8])\n",
    "        ax1.plot(loss, 'b')\n",
    "        ax1.set_xlabel(\"epoch\")\n",
    "        ax1.set_ylabel(\"loss\")\n",
    "        ax2.plot(accuracy, 'r')\n",
    "        ax2.set_xlabel(\"epoch\")\n",
    "        ax2.set_ylabel(\"accuracy\")\n",
    "        plt.show()\n",
    "    model.save_weights(\"weights/weight_untrained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c35381",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataset/dataset.txt', mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "train(data,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4677e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = 87\n",
    "def generate_music(initial, length):\n",
    "    with open('char_to_index.json') as json_file:\n",
    "        char_to_index = json.load(json_file)\n",
    "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = 87, output_dim = 512, batch_input_shape = (1, 1))) \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add((Dense(87)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.load_weights(\"weights/weights.h5\")\n",
    "    sequence_index = [initial]\n",
    "    \n",
    "    for _ in range(length):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = sequence_index[-1]\n",
    "        \n",
    "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(unique_chars), size = 1, p = predicted_probs)\n",
    "        \n",
    "        sequence_index.append(sample[0])\n",
    "    \n",
    "    seq = ''.join(index_to_char[c] for c in sequence_index)\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in seq:\n",
    "        cnt += 1\n",
    "        if i == \"\\n\":\n",
    "            break\n",
    "    seq1 = seq[cnt:]\n",
    "    cnt = 0\n",
    "    for i in seq1:\n",
    "        cnt += 1\n",
    "        if i == \"\\n\" and seq1[cnt] == \"\\n\":\n",
    "            break\n",
    "    seq2 = seq1[:cnt]\n",
    "    return seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd025c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_music(47,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05d3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1a40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
